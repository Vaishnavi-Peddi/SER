# SER
# ğŸ™ï¸ Speech Emotion Recognition (SER) Project

This project is a **Speech Emotion Recognition (SER)** system that identifies human emotions (e.g., happy, sad, angry) from audio recordings. It supports multilingual audio input (Telugu, Hindi, English) and uses a combination of **CNN-LSTM deep learning** for raw audio emotion classification and **NLP-based text analysis** using **GoEmotions** for emotion detection from transcribed speech.

## ğŸš€ Features

- ğŸ§ Recognizes emotions from speech audio files
- ğŸŒ Multilingual: Telugu, Hindi, English
- ğŸ”Š Uses CNN + LSTM model trained on the RAVDESS dataset
- ğŸ§  Integrates GoEmotions for text-based emotion inference
- ğŸ”„ Speech-to-text with automatic translation (if needed)
- ğŸŒ Web interface for uploading and analyzing emotions
- ğŸ“Š Displays emotion with emoji and probability

## ğŸ› ï¸ Tech Stack

- **Frontend**: HTML, CSS, Bootstrap
- **Backend**: Python (Flask)
- **Machine Learning**:
  - CNN-LSTM model for audio classification
  - Transformers (Hugging Face) for text emotion detection
- **Speech Recognition**: `speech_recognition`, `ffmpeg`
- **Translation**: `deep_translator` (Google Translator API)
- **Visualization**: Emojis and probability graphs (optional)

## ğŸ“ Project Structure

```
SER/
â”‚
â”œâ”€â”€ app.py                       # Flask server
â”œâ”€â”€ prediction_model.py         # Audio emotion model (CNN+LSTM)
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html              # Main web UI
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css               # Styling (if needed)
â”œâ”€â”€ uploads/                    # Stores uploaded audio
â”œâ”€â”€ processed/                  # Preprocessed/converted audio
â”œâ”€â”€ requirements.txt            # Required Python packages
â””â”€â”€ README.md                   # Project documentation
```

## ğŸ”§ Setup Instructions

1. **Clone the repository**
   ```bash
   git clone https://github.com/Vaishnavi-Peddi/SER.git
   cd SER
   ```

2. **Create a virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate   # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Start the Flask app**
   ```bash
   python app.py
   ```

5. **Open in browser**
   ```
   http://127.0.0.1:5000/
   ```

## ğŸ“ Datasets Used

- **RAVDESS**: For audio-based training and testing
- **GoEmotions**: For emotion labeling via text

## ğŸ§ª Example Emotions Detected

| Language | Input Text/Speech         | Emotion Output |
|----------|----------------------------|----------------|
| English  | "Iâ€™m so happy today!"      | ğŸ˜€ Happy       |
| Hindi    | "à¤®à¥à¤à¥‡ à¤—à¥à¤¸à¥à¤¸à¤¾ à¤† à¤°à¤¹à¤¾ à¤¹à¥ˆ"     | ğŸ˜  Angry       |
| Telugu   | "à°¨à°¾à°•à± à°šà°¾à°²à°¾ à°¬à°¾à°§à°—à°¾ à°‰à°‚à°¦à°¿"     | ğŸ˜¢ Sad         |

## ğŸ“Œ To-Do / Enhancements

- [ ] Add multi-user login and emotion history
- [ ] Enable live microphone input
- [ ] Deploy on cloud (Render/Heroku/AWS)
- [ ] Add emotion graph or timeline

## âœ… Requirements

- Python 3.8+
- `ffmpeg` installed and added to system PATH

## ğŸ“¦ Dependencies

```
Flask
speechrecognition
deep-translator
transformers
torch
torchaudio
librosa
ffmpeg-python
```

You can install them all using:
```bash
pip install -r requirements.txt
```

## ğŸ§‘â€ğŸ’» Contributors

- Vaishu (Project Lead)
- [YourName] (Model Development)
- [Optional Contributor]

## ğŸ“„ License

This project is open-source under the [MIT License](LICENSE).

---

Made with â¤ï¸ for emotion-aware computing!
